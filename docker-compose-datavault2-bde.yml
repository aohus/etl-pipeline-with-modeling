version: "3"
networks:
  default:
    name: docker-hadoop-poc

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    ports:
      - 9870:9870
      - 8020:8020

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    ports:
      - 9864:9864

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    ports:
      - "8032:8032"
      - "8088:8088"

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    ports:
      - "8042:8042"

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    ports:
      - "8188:8188"

  hive-metastore-mysql:
    image: mysql:8.0.21
    container_name: hive-metastore-mysql
    hostname: hive-metastore-mysql
    command: --default-authentication-plugin=mysql_native_password --lower-case-table-names=1
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: metastore
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
    ports:
      - "3306:3306"

  hive-server:
    image: kadensungbincho/hadoop-hive-mysql:hive3.1.2-hadoop3.2.1-java8
    container_name: hive-server
    hostname: hive-server
    depends_on:
      - resourcemanager
      - nodemanager
      - historyserver
      - hive-metastore
    volumes:
      - ./dummy_data:/opt/dummy_data
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    environment:
      SERVICE_PRECONDITION: "hive-metastore:9083"
      DUMMY_DATA: 1
    ports:
      - 10000:10000

  hive-metastore:
    image: kadensungbincho/hadoop-hive-mysql:hive3.1.2-hadoop3.2.1-java8
    container_name: hive-metastore
    hostname: hive-metastore
    depends_on:
      - hive-metastore-mysql
    env_file:
      - ./examples/datavault2-example/hadoop/hadoop.env
    command: [ "startup.sh", "metastore" ]
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-mysql:3306"
    ports:
      - "9083:9083"

  zookeeper:
    image: zookeeper:3.4.14
    restart: always
    hostname: zookeeper
    ports:
      - 2181:2181

  postgres:
    image: postgres:9.6
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - 5432:5432
    volumes:
      - ./examples/datavault2-example/setup/100_create_database.sql:/docker-entrypoint-initdb.d/100_create_database.sql
      - ./examples/datavault2-example/setup/200_create_tables.sql:/docker-entrypoint-initdb.d/200_create_tables.sql
      - ./examples/datavault2-example/setup/300_permissions.sql:/docker-entrypoint-initdb.d/300_permissions.sql
      - ./examples/datavault2-example/setup/data:/docker-entrypoint-initdb.d/data

  webserver:
    build:
      context: ./examples/datavault2-example
      dockerfile: airflow.dockerfile
    container_name: airflow
    restart: always
    depends_on:
      - postgres
      - hive-server
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - INSTALL_HIVE=y
    volumes:
      - ./examples/datavault2-example/dags:/usr/local/airflow/dags
      - ./examples/datavault2-example/sql:/usr/local/airflow/sql
      - ./examples/datavault2-example/hadoop/core-site.xml:/core-site.xml
      - ./examples/datavault2-example/hadoop/hdfs-site.xml:/hdfs-site.xml
      - ./examples/datavault2-example/hadoop/mapred-site.xml:/mapred-site.xml
    #   - ./examples/datavault2-example/airflow.cfg:/usr/local/airflow/airflow.cfg
    #   - ./.keyfile.json:/usr/local/airflow/keyfile.json:ro
    ports:
      - "8080:8080"
    command: webserver


volumes:
  namenode:
  datanode:
  hadoop_historyserver: